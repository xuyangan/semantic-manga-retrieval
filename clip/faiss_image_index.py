#!/usr/bin/env python3
"""
FAISS Index Builder for Manga Image Search

Creates a FAISS index from pre-computed CLIP image embeddings.
Uses embeddings generated by image_embeddings.py.

Usage:
    python clip/faiss_image_index.py final_dataset_embeddings
    python clip/faiss_image_index.py final_dataset_embeddings --output-dir custom_index
    python clip/faiss_image_index.py final_dataset_embeddings --use-ivf
    python clip/faiss_image_index.py --search final_dataset_embeddings/faiss_index --query image.png
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import TYPE_CHECKING

import numpy as np

if TYPE_CHECKING:
    from numpy.typing import NDArray

# Lazy imports
_faiss = None


def _get_faiss():
    """Lazy load FAISS to avoid import conflicts."""
    global _faiss
    if _faiss is None:
        import faiss
        _faiss = faiss
    return _faiss


class ImageFaissIndex:
    """
    FAISS index for manga image similarity search.
    Uses L2-normalized embeddings with Inner Product (= cosine similarity).
    """
    
    __slots__ = ('dimension', 'index', 'id_to_meta', '_next_id')
    
    def __init__(self, dimension: int = 768, use_ivf: bool = False, nlist: int = 100):
        """
        Initialize the index.
        
        Args:
            dimension: Embedding dimension (768 for CLIP ViT-L-14)
            use_ivf: Use IVF index for faster search on large datasets
            nlist: Number of clusters for IVF index
        """
        faiss = _get_faiss()
        self.dimension = dimension
        
        if use_ivf:
            quantizer = faiss.IndexFlatIP(dimension)
            self.index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)
        else:
            self.index = faiss.IndexFlatIP(dimension)
        
        self.id_to_meta: dict[int, dict] = {}
        self._next_id = 0
    
    def add(self, embeddings: NDArray[np.float32], metadata_list: list[dict]) -> None:
        """
        Add embeddings to the index with metadata.
        
        Args:
            embeddings: L2-normalized embedding vectors (N x D)
            metadata_list: List of metadata dicts for each embedding
        """
        if len(embeddings) == 0:
            return
        
        faiss = _get_faiss()
        
        # Ensure float32 and normalize
        embeddings = np.ascontiguousarray(embeddings, dtype=np.float32)
        faiss.normalize_L2(embeddings)
        
        # Train IVF index if needed
        if hasattr(self.index, 'is_trained') and not self.index.is_trained:
            print(f"Training IVF index with {len(embeddings)} vectors...")
            self.index.train(embeddings)
        
        # Store metadata
        start_id = self._next_id
        for i, meta in enumerate(metadata_list):
            int_id = start_id + i
            self.id_to_meta[int_id] = meta
        
        self._next_id = start_id + len(metadata_list)
        
        # Add to index
        self.index.add(embeddings)
        print(f"Indexed {len(embeddings)} images (total: {self.index.ntotal})")
    
    def search(self, query: NDArray[np.float32], k: int = 10) -> list[dict]:
        """
        Search for similar images.
        
        Args:
            query: Query embedding (D,) or (1, D)
            k: Number of results
        
        Returns:
            List of results with similarity scores and metadata
        """
        faiss = _get_faiss()
        
        query = np.ascontiguousarray(
            query.reshape(1, -1) if query.ndim == 1 else query,
            dtype=np.float32
        )
        faiss.normalize_L2(query)
        
        scores, indices = self.index.search(query, k)
        
        return [
            {"rank": i + 1, "similarity": float(score), **self.id_to_meta[idx]}
            for i, (score, idx) in enumerate(zip(scores[0], indices[0]))
            if idx != -1 and idx in self.id_to_meta
        ]
    
    def search_batch(self, queries: NDArray[np.float32], k: int = 10) -> list[list[dict]]:
        """Batch search for multiple queries."""
        faiss = _get_faiss()
        
        queries = np.ascontiguousarray(queries, dtype=np.float32)
        faiss.normalize_L2(queries)
        
        scores, indices = self.index.search(queries, k)
        
        results = []
        for q_scores, q_indices in zip(scores, indices):
            q_results = [
                {"rank": i + 1, "similarity": float(score), **self.id_to_meta[idx]}
                for i, (score, idx) in enumerate(zip(q_scores, q_indices))
                if idx != -1 and idx in self.id_to_meta
            ]
            results.append(q_results)
        
        return results
    
    def save(self, output_dir: Path) -> None:
        """Save index and metadata to disk."""
        faiss = _get_faiss()
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        faiss.write_index(self.index, str(output_dir / "faiss.index"))
        
        data = {
            "dimension": self.dimension,
            "total": self.index.ntotal,
            "index_type": type(self.index).__name__,
            "metadata": {str(k): v for k, v in self.id_to_meta.items()},
        }
        with open(output_dir / "metadata.json", "w") as f:
            json.dump(data, f, indent=2)
        
        print(f"Saved index ({self.index.ntotal} vectors) to {output_dir}")
    
    @classmethod
    def load(cls, index_dir: Path) -> ImageFaissIndex:
        """Load index from disk."""
        faiss = _get_faiss()
        index_dir = Path(index_dir)
        
        index = faiss.read_index(str(index_dir / "faiss.index"))
        
        with open(index_dir / "metadata.json") as f:
            data = json.load(f)
        
        instance = cls.__new__(cls)
        instance.index = index
        instance.dimension = data.get("dimension", index.d)
        instance.id_to_meta = {int(k): v for k, v in data["metadata"].items()}
        instance._next_id = max(instance.id_to_meta.keys(), default=-1) + 1
        
        print(f"Loaded index with {index.ntotal} vectors")
        return instance
    
    def get_by_id(self, int_id: int) -> dict | None:
        """Get metadata by integer ID."""
        return self.id_to_meta.get(int_id)
    
    def get_embedding(self, int_id: int) -> NDArray[np.float32] | None:
        """Reconstruct embedding for an ID."""
        if int_id not in self.id_to_meta:
            return None
        return self.index.reconstruct(int_id)
    
    def __len__(self) -> int:
        return self.index.ntotal


def load_embeddings_from_dir(embeddings_dir: Path) -> tuple[np.ndarray, list[dict]]:
    """
    Load embeddings and metadata from directory created by image_embeddings.py.
    
    Args:
        embeddings_dir: Directory containing all_embeddings.npy and metadata.json
    
    Returns:
        tuple: (embeddings array, metadata list)
    """
    embeddings_dir = Path(embeddings_dir)
    
    # Load embeddings
    embeddings_path = embeddings_dir / "all_embeddings.npy"
    if not embeddings_path.exists():
        raise FileNotFoundError(f"Embeddings not found: {embeddings_path}")
    
    embeddings = np.load(embeddings_path)
    print(f"Loaded embeddings: {embeddings.shape}")
    
    # Load metadata
    metadata_path = embeddings_dir / "metadata.json"
    if not metadata_path.exists():
        raise FileNotFoundError(f"Metadata not found: {metadata_path}")
    
    with open(metadata_path) as f:
        data = json.load(f)
    
    metadata_list = data.get("files", [])
    print(f"Loaded metadata for {len(metadata_list)} files")
    
    if len(embeddings) != len(metadata_list):
        print(f"Warning: embeddings ({len(embeddings)}) and metadata ({len(metadata_list)}) count mismatch")
    
    return embeddings, metadata_list


def build_index(
    embeddings_dir: Path,
    output_dir: Path = None,
    use_ivf: bool = False,
) -> ImageFaissIndex:
    """
    Build FAISS index from pre-computed embeddings.
    
    Args:
        embeddings_dir: Directory containing embeddings from image_embeddings.py
        output_dir: Output directory for index (default: embeddings_dir/faiss_index)
        use_ivf: Use IVF index for faster search
    
    Returns:
        ImageFaissIndex instance
    """
    print(f"\n{'='*60}")
    print("  FAISS Image Index Builder")
    print(f"{'='*60}")
    
    # Load embeddings
    print(f"\nLoading embeddings from: {embeddings_dir}")
    embeddings, metadata_list = load_embeddings_from_dir(embeddings_dir)
    
    if len(embeddings) == 0:
        raise ValueError("No embeddings found")
    
    # Build index
    print("\nBuilding index...")
    index = ImageFaissIndex(
        dimension=embeddings.shape[1],
        use_ivf=use_ivf,
        nlist=min(100, len(embeddings) // 10) if use_ivf else 100
    )
    index.add(embeddings, metadata_list)
    
    # Save
    if output_dir is None:
        output_dir = embeddings_dir / "faiss_index"
    
    index.save(output_dir)
    
    print(f"\n{'='*60}")
    print(f"  Done! {len(index)} images indexed")
    print(f"{'='*60}\n")
    
    return index


def visualize_search_results(
    query_image_path: Path,
    results: list[dict],
    output_path: Path = None,
    show: bool = True
):
    """
    Visualize search results with query image and similar images.
    
    Args:
        query_image_path: Path to query image
        results: List of search results with metadata
        output_path: Optional path to save the visualization
        show: Whether to display the plot
    """
    import matplotlib.pyplot as plt
    from PIL import Image
    
    n_results = len(results)
    if n_results == 0:
        print("No results to visualize")
        return
    
    # Create figure: query on left, results on right
    fig, axes = plt.subplots(1, n_results + 1, figsize=(3 * (n_results + 1), 4))
    
    # Plot query image
    query_img = Image.open(query_image_path).convert("RGB")
    axes[0].imshow(query_img)
    axes[0].set_title("Query", fontsize=10, fontweight='bold')
    axes[0].axis('off')
    
    # Plot result images
    for i, r in enumerate(results):
        ax = axes[i + 1]
        
        # Try to load result image
        img_path = r.get('path')
        if img_path and Path(img_path).exists():
            try:
                img = Image.open(img_path).convert("RGB")
                ax.imshow(img)
            except Exception as e:
                ax.text(0.5, 0.5, f"Error:\n{e}", ha='center', va='center', fontsize=8)
        else:
            ax.text(0.5, 0.5, "Image not found", ha='center', va='center', fontsize=8)
        
        # Title with similarity and metadata
        manga = r.get('manga', 'unknown')
        chapter = r.get('chapter', 'unknown')
        page = r.get('page', 'unknown')
        sim = r.get('similarity', 0)
        
        # Truncate manga name if too long
        if len(manga) > 15:
            manga = manga[:12] + "..."
        
        ax.set_title(f"#{r['rank']} ({sim:.2f})\n{manga}\n{chapter}/{page}", fontsize=8)
        ax.axis('off')
    
    plt.tight_layout()
    
    if output_path:
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"Saved visualization to: {output_path}")
    
    if show:
        plt.show()
    else:
        plt.close()


def search_demo(index_dir: Path, query_image: Path = None, k: int = 5, visualize: bool = False, save_viz: Path = None):
    """
    Demo search functionality.
    
    Args:
        index_dir: Path to FAISS index directory
        query_image: Optional query image path
        k: Number of results to return
        visualize: Whether to visualize results
        save_viz: Optional path to save visualization
    """
    print("\n=== Search Demo ===")
    
    # IMPORTANT: Load CLIP model BEFORE FAISS to avoid segfault on macOS
    # There's a known conflict between FAISS and PyTorch when loaded in wrong order
    if query_image:
        import torch
        import open_clip
        from PIL import Image
        
        print("Loading CLIP model for query encoding...")
        model, preprocess, _ = open_clip.create_model_and_transforms(
            "ViT-L-14",
            pretrained="laion2b_s32b_b82k",
        )
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = model.to(device).eval()
        
        # Encode query image
        img = preprocess(Image.open(query_image).convert("RGB")).unsqueeze(0).to(device)
        with torch.no_grad():
            emb = model.encode_image(img)
            emb = (emb / emb.norm(dim=-1, keepdim=True)).cpu().numpy()
        
        # Now load FAISS index (after PyTorch is loaded)
        index = ImageFaissIndex.load(index_dir)
        
        results = index.search(emb, k=k)
        print(f"\nQuery: {query_image}")
        
        # Visualize if requested
        if visualize or save_viz:
            visualize_search_results(query_image, results, output_path=save_viz, show=visualize)
    else:
        # No query image - safe to load FAISS directly
        index = ImageFaissIndex.load(index_dir)
        
        first_id = min(index.id_to_meta.keys())
        meta = index.id_to_meta[first_id]
        query_path = meta.get('path')
        print(f"\nQuery: {meta.get('manga', 'unknown')}/{meta.get('chapter', 'unknown')}/{meta.get('page', 'unknown')}")
        
        emb = index.get_embedding(first_id)
        results = index.search(emb, k=k + 1)[1:]  # Skip self
        
        # Visualize if requested and query path exists
        if (visualize or save_viz) and query_path and Path(query_path).exists():
            visualize_search_results(Path(query_path), results, output_path=save_viz, show=visualize)
    
    print("\nResults:")
    for r in results:
        manga = r.get('manga', 'unknown')
        chapter = r.get('chapter', 'unknown')
        page = r.get('page', 'unknown')
        print(f"  {r['rank']}. [{r['similarity']:.3f}] {manga}/{chapter}/{page}")


def main():
    parser = argparse.ArgumentParser(
        description="FAISS index for manga image search",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Build index from embeddings
    python clip/faiss_image_index.py final_dataset_embeddings
    
    # Build with IVF for large datasets
    python clip/faiss_image_index.py final_dataset_embeddings --use-ivf
    
    # Search with query image
    python clip/faiss_image_index.py --search final_dataset_embeddings/faiss_index --query image.png
    
    # Search with visualization
    python clip/faiss_image_index.py --search final_dataset_embeddings/faiss_index --query image.png --visualize
    
    # Search and save visualization
    python clip/faiss_image_index.py --search final_dataset_embeddings/faiss_index --query image.png --save-viz results.png
    
    # Demo search (uses first indexed image)
    python clip/faiss_image_index.py --search final_dataset_embeddings/faiss_index
        """
    )
    parser.add_argument(
        "embeddings_dir",
        type=str,
        nargs="?",
        default=None,
        help="Directory containing embeddings from image_embeddings.py",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="Output directory for FAISS index (default: embeddings_dir/faiss_index)",
    )
    parser.add_argument(
        "--use-ivf",
        action="store_true",
        help="Use IVF index (faster for large datasets)",
    )
    parser.add_argument(
        "--search",
        type=str,
        default=None,
        help="Path to existing FAISS index directory for search",
    )
    parser.add_argument(
        "--query",
        type=str,
        default=None,
        help="Query image path for search demo",
    )
    parser.add_argument(
        "-k",
        type=int,
        default=5,
        help="Number of search results (default: 5)",
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="Display visualization of search results",
    )
    parser.add_argument(
        "--save-viz",
        type=str,
        default=None,
        help="Save visualization to file (e.g., results.png)",
    )
    
    args = parser.parse_args()
    
    if args.search:
        # Search mode
        index_dir = Path(args.search)
        query_image = Path(args.query) if args.query else None
        save_viz = Path(args.save_viz) if args.save_viz else None
        search_demo(index_dir, query_image, k=args.k, visualize=args.visualize, save_viz=save_viz)
    elif args.embeddings_dir:
        # Build mode
        embeddings_dir = Path(args.embeddings_dir)
        if not embeddings_dir.exists():
            print(f"Error: Embeddings directory not found: {embeddings_dir}")
            return
        
        output_dir = Path(args.output_dir) if args.output_dir else None
        build_index(embeddings_dir, output_dir, args.use_ivf)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
